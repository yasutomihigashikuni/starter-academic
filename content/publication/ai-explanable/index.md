---
title: "An explainable artificial intelligence-enabled electrocardiogram analysis model for the classification of reduced left ventricular function"
publication_types:
  - "2"
authors:
  - Susumu Katsushika 
  - Satoshi Kodera
  - Shinnosuke Sawano
  - Hiroki Shinohara
  - Naoto Setoguchi
  - Kengo Tanabe
  - admin
  - Norifumi Takeda
  - Katsuhito Fujiu
  - Masao Daimon
  - Hiroshi Akazawa
  - Hiroyuki Morita
  - Issei Komuro
date: 2023-04-17T20:34:17.125Z
doi: 10.1093/ehjdh/ztad027
publication: Eur Heart J Digit Health. 2023;4(3):254-264
abstract: Aims, The black box nature of artificial intelligence (AI) hinders the development of interpretable AI models that are applicable in clinical practice. We aimed to develop an AI model for classifying patients of reduced left ventricular ejection fraction (LVEF) from 12-lead electrocardiograms (ECG) with the decision-interpretability. Methods and results, We acquired paired ECG and echocardiography datasets from the central and co-operative institutions. For the central institution dataset, a random forest model was trained to identify patients with reduced LVEF among 29 907 ECGs. Shapley additive explanations were applied to 7196 ECGs. To extract the model's decision criteria, the calculated Shapley additive explanations values were clustered for 192 non-paced rhythm patients in which reduced LVEF was predicted. Although the extracted criteria were different for each cluster, these criteria generally comprised a combination of six ECG findings: negative T-wave inversion in I/V5-6 leads, low voltage in I/II/V4-6 leads, Q wave in V3-6 leads, ventricular activation time prolongation in I/V5-6 leads, S-wave prolongation in V2-3 leads, and corrected QT interval prolongation. Similarly, for the co-operative institution dataset, the extracted criteria comprised a combination of the same six ECG findings. Furthermore, the accuracy of seven cardiologists' ECG readings improved significantly after watching a video explaining the interpretation of these criteria (before, 62.9% ± 3.9% vs. after, 73.9% ± 2.4%; P = 0.02). Conclusion, We visually interpreted the model's decision criteria to evaluate its validity, thereby developing a model that provided the decision-interpretability required for clinical application.

featured: false
tags: 
  - AI
image:
  filename: featured
  focal_point: Smart
  preview_only: false
projects: 
- artificial-intelligence
---
